Questions / Tasks,Task Category Coding,Other Notes
P1:,,
what are relevant to class 1 or class 2? ,outcome-feature logic,
check how the subpopulation narrows down,feature-outcome logic,
what features are in common for default (what are relevant to class 1 or class 2? ),outcome-feature logic,
what are the most important features,feature relevance,
whether two subgroups contain the same group of people?,subgroup comparison,one-off case
want to know the proportion of the first node compared to the whole dataset,?,Ignore. It more like an aspect of the way we visualize things.
interested in changing cutoff value,threshold adjustment,
want to know more about the feature description (not familiar with the feature),?,Out of scope. Ignore.
P2:,,
generate the rules that has higher fidelity,model search,
generate a rule set with few rules,model search,
what factors are most important for default? (determinative features),outcome-feature logic,
"what factors (condition) that covers the most default instances? (if a person if diabetic, what is the most probable feature value)",outcome-feature logic,
look for nodes with high fidelity,rule search / exploration,
what factors are important to indicate no-default?,outcome-feature logic,
what are the conditions that by its own it leads to a quite pure node,rule search / exploration,
"any feature on its own that are mostly class A, but combined with another feature, it may flip the prediction",rule search / exploration,
P3:,,
which condition/rule covers the most instances? (because it explains the most decisions in general),rule search / exploration,
what features are used for model description,feature relevance,
find the threshold of the feature that leads to different predictions,threshold adjustment,
what's the relationship b/w feature of second largest node with prediction,feature-outcome logic,
"whether it is enough to predict class A using one feature, if not how other feature influence it?",outcome-feature logic,
look at the low-layers to see whether it makes the fidelity higher,rule search / exploration,
check whether the feature value change can lead to different prediction?,threshold adjustment,
reason the features with errors (relationship b/w feat and error),feature-error logic,
what features are used in the shorter rules ,feature relevance,
whether the usage of a feature increase or decrease errors,feature-error logic,
check how the error rate changes from layer to layer,feature-error logic,
P4:,,
getting familiar with the dataset,?,Ignore. Too vague.
"get the most frequently used feature, it is does not match my memory (usually last delinq. is more relevant)",feature relevance,
whether the number of rules for each class makes sense,?,Ignore. Not clear.
understanding the relationship b/w one feature (%trades w/ b) and the outcome in general ,feature-outcome logic,
focus on the rules that contain only one condition,rule search / exploration,
interested in the features used less(last column)/ try to start from a simple case,feature relevance,
validate the threshold of feature,threshold adjustment,
validate the relationship of feature with prediction (feature ,feature-outcome logic,
check the distribution of the features,feature properties,one-off case
check the monotonicity,feature-outcome logic,
has some doubts on the three bins (can be divided differently for U curve),threshold adjustment,
check the relationship between one feature itself and the model predictions ,feature-outcome logic,
check feature interaction (combination of features matters),feature-outcome logic (interactions),
why does two box look similar? how are the rules different and the subpopulation different?,rule comparison,one-off case
understand where the model does not work well,rule search / exploration,
look for terminal nodes in the lattice view,rule search / exploration,
(for error) look for box large enough and contain reasonable number of errors (how to balance size of box and #errors),rule search / exploration,
P5:,,
"what are the features that are used, what ",?,Not clear. Ignore.
what are the rules leads to Default,outcome-feature logic,
find the most important features ,feature relevance,
what feature/condtion stands out in No Default,outcome-feature logic,
"use fewer rules to cover most cases of No Default,",model search,
check the text of selected nodes,?,ignore
summarize the influence of top features,feature-outcome logic,
"check the influence of a feature of interest (based on prior knowledge,e.g. avg months in file)",feature-outcome logic,
want to see the first bin of avg. month narrower,threshold adjustment,
P6:,,
which features may lead to the two predictions,outcome-feature logic,
Is there any subgroup with good bills paid on time predicted as default,rule search / exploration,
what are more detailed behaviors of the model on a subgroup when other conditions are added,user-defined rule,one-off case
get a simpler rule description of the whole model,model search,
create minimal description of whole data set--> find the node covers the rest unselected data,model search,
P7:,,
how to get the simplest rules,model search,
how the feature values are relevant to prediction,feature-outcome logic,
"find the strong nodes ""large enough and divide the classes well""",rule search / exploration,
what are the condition(s) lead to default,outcome-feature logic,
how one feature is relevant to the prediction,feature-outcome logic,